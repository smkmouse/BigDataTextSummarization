#!/usr/bin/env python3

#Part 2 of the template summary script.
#Requires the file generated by part 1 as an input and the named Entity file
#File format is newline-delimited strings of interesting named-entity/verb pairs.
#Warning: loads full file into memory.

inFile = "templateProcessOutputBigLDA.txt"
namedEntityFile = "namedEntityResultsBigLDA.txt"

import re

def entity(str):
    return str.split('|')[1]

def subject(str):
    return str.split('|')[0]

def mergeEnt(str):
    temp = str.split('|')
    return temp[0]+" "+temp[1]

def look(strings, searchStr):
    list = []
    for s in strings:
        if searchStr in s:
            list.append(s)
    return list

def lookMulti(strings, searchList):
    list = []
    first = True
    for searchItem in searchList:
        if first:
            first = False
            list = look(strings, searchItem)
        else:
            list = look(list, searchItem) #search only in previous good results
    return list

def most_common(lst):
    return max(set(lst), key=lst.count)

def english_lister(strlist, number):
        string = ""
        for i in range(0, number):
            if i is number-1:
                string+="and "
            string += strlist[i]
            if i is not number-1:
                string+=", "
        return string



def intelliGrab(strings, searchList, regex, getEntity):
    list = lookMulti(strings, searchList) #get strings that contain all search words
    if getEntity is "entity":
        list = [entity(x) for x in list]
    elif getEntity is "subject":
        list = [subject(x) for x in list]
    else: #both
        list = [mergeEnt(x) for x in list]
    #sort on len smallest first (smaller results are more releveant, will be picked up by regex first)
    list.sort(key = len)

    #match based on regex
    return re.search(regex, str(list)).group()

def regexNE(sentences, entityType, regex):
    #go thru sentences, look for ones with both gpe and regex of interest. Filter by common
    goodSentences = []
    goodWords = []
    for sentence in sentences:
        hasEntity = False
        hasSearchString = False
        goodWord = ""
        textSentence = ""
        for word in sentence:
            textSentence += word[0]
            if entityType in word[1]:
                hasEntity = True
                goodWord = word[0]
        if re.search(regex, textSentence):
            hasSearchString = True
        if hasEntity and hasSearchString:
            goodSentences.append(sentence)
            goodWords.append(goodWord)

    goodWordsDict = {}
    for x in goodWords:
        try:
            goodWordsDict[x] = goodWordsDict[x]+1
        except KeyError:
            goodWordsDict[x] = 1

    tmp = sorted([(value, key) for (key,value) in goodWordsDict.items()], reverse = True)
    goodWordsDedup = [y for x,y in tmp]
    print(tmp)

    return goodWordsDedup

if __name__ == "__main__":
    strings = []
    sentences = [] #list of sentences, where periods mean new sentence
    wordTypes = [] #word:type tuple list

    with open(inFile) as f:
        for line in f:
            strings.append(line[:-1].lower())
    with open(namedEntityFile) as f:
        #load file as sentences only and as word:type pairs
        sentence = []
        for line in f:
            word = line.split(" ")
            if len(word) is 2:
                sentence.append((word[0],word[1][:-1]))
                if word[0] is ".":
                    sentences.append(sentence)
                    sentence=[]
                wordTypes.append((word[0],word[1][:-1]))

    #to extract one, use regexNE, and take the first result
    #to extract multiple, use regexNE and send the output into the english lister,
    #which gives a specified length list in english of the items returned by regexNE
    windspeed = regexNE(sentences, "QUANTITY", "wind.*mph")[0]
    deaths = regexNE(sentences, "CARDINAL", "\d+.*deaths")[0]
    damagePlaces = english_lister(regexNE(sentences, "GPE", "damage"), 7)
    power = regexNE(sentences, "CARDINAL", "power.*outage")[0]
    orgs = english_lister(regexNE(sentences, "ORG", ".*"), 7)
    looting = regexNE(sentences, "GPE", "looting")[0]
    category = regexNE(sentences, "CARDINAL", "category")[0]
    landfallDate = regexNE(sentences, "DATE", "landfall")[0]
    landfallPlace = regexNE(sentences, "GPE", "landfall")[0]
    evacuations = regexNE(sentences, "CARDINAL", "people.*evacuated")[0]


    print("Hurricane Michael, a category "+category+" hurricane, made landfall on "+landfallDate+" in "+landfallPlace+"." )
    print("The wind speeds were measured at "+windspeed+", and the hurricane caused "+deaths+" deaths as it traveled onto land.")
    print("The largest amount of damage took place in "+damagePlaces+".")
    print(power+" homes lost power.")
    print(orgs+" were working to document the damage and assist the victims.")
    print("There were also reports of looting in "+looting+".")
    print(evacuations+" people were evacuated from their homes by authorities in anticipation of the storm.")
